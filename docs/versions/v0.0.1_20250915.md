# GEPP Platform Backend Architecture Overview v0.0.1

**Date:** 2025-09-15
**Author:** Claude Code Assistant
**Purpose:** Comprehensive technical documentation for backend architecture understanding

## Executive Summary

The GEPP Platform backend is a comprehensive waste management and environmental reporting system built with Python/SQLAlchemy. It implements a multi-tenant architecture supporting Extended Producer Responsibility (EPR), rewards systems, knowledge management, GRI reporting, and user management across various business domains.

## Architecture Overview

### Core Technology Stack
- **Framework:** Python with SQLAlchemy ORM
- **Database:** PostgreSQL with spatial extensions (GeoAlchemy2)
- **Authentication:** JWT with bcrypt password hashing
- **Deployment:** AWS Lambda functions (serverless)

### Directory Structure
```
backend/
‚îú‚îÄ‚îÄ GEPPPlatform/
‚îÇ   ‚îú‚îÄ‚îÄ models/          # Data models and database schemas
‚îÇ   ‚îú‚îÄ‚îÄ services/        # Business logic and API endpoints
‚îÇ   ‚îú‚îÄ‚îÄ libs/           # Shared utilities and libraries
‚îÇ   ‚îú‚îÄ‚îÄ database.py     # Database connection management
‚îÇ   ‚îî‚îÄ‚îÄ __init__.py
‚îú‚îÄ‚îÄ migrations/         # Database migration scripts
‚îî‚îÄ‚îÄ docs/              # Documentation
```

## Models Architecture

### Base Infrastructure (`models/base.py`)
- **Base Model Pattern:** Common fields for all entities (id, is_active, created_date, updated_date, deleted_date)
- **Platform Enum:** Multi-platform support (gepp_business_web, gepp_epr_web, gepp_reward_app, etc.)
- **SQLAlchemy Declarative Base:** Foundation for all model classes

### Domain Models Structure

#### 1. Core Models (`models/cores/`)
**Purpose:** Foundational reference data and system-wide configurations
- **Location Hierarchy:** Countries ‚Üí Provinces ‚Üí Districts ‚Üí Subdistricts
- **Reference Data:** Currencies, materials, nationalities, phone codes, banks
- **Permissions System:** Role-based access control with permission types
- **Translations:** Multi-language support infrastructure

#### 2. User Management (`models/users/`)
**Purpose:** Unified user and location management with organizational hierarchy

**Key Concept - UserLocation Model:**
- **Dual Purpose Entity:** Can serve as both user accounts (`is_user=True`) and waste transaction locations (`is_location=True`)
- **Organizational Tree Structure:**
  - Direct hierarchy: `parent_user_id` ‚Üí `direct_children`
  - Flexible many-to-many: `subusers` relationship via association table
  - Materialized path: `organization_path` for efficient tree queries
  - Level tracking: `organization_level` for depth management

**Business Domain Fields:**
- Authentication: email, password, social login IDs
- Business Profile: company info, tax ID, business type/industry
- Geographic: coordinates, full address hierarchy
- Waste Management: functions (collector/recycler/sorter), materials handled
- Compliance: national ID, business certificates

#### 3. Subscription Management (`models/subscriptions/`)
**Purpose:** Multi-tenant SaaS architecture with tiered service levels
- **Organizations:** Business entities with subscription plans
- **Subscription Plans:** Free/paid tiers with feature limitations
- **Permission System:** Organization-level and system-level permissions

#### 4. Transaction Management (`models/transactions/`)
**Purpose:** Waste tracking and material flow management

**Architecture Pattern:**
- **Transaction (Batch Level):** Groups multiple records moving together
- **TransactionRecord (Item Level):** Individual material quantities
- **Supporting Models:** Material conditions, processing stages, verification, audit trails

**Status Flow:** draft ‚Üí scheduled ‚Üí in_progress ‚Üí in_transit ‚Üí delivered ‚Üí completed

#### 5. EPR (Extended Producer Responsibility) (`models/epr/`)
**Purpose:** Regulatory compliance for producers and importers

**Core Components:**
- **EprOrganization:** Companies in EPR programs with registration/licensing
- **EprBrand/Product:** Product catalog for compliance tracking
- **EprProject:** Compliance projects with file management and user assignments
- **EprPro:** Professional services with material group management
- **Auditing System:** Transaction assignments and auditor workflows

#### 6. EPR Payments (`models/epr_payments/`)
**Purpose:** Financial transactions for EPR compliance fees
- **Payment Transactions:** Fee calculations and payment records
- **Assistant Fees:** Project-based fee structures and calculations
- **Monthly Spending:** Actual vs projected cost tracking

#### 7. GRI Reporting (`models/gri/`)
**Purpose:** Global Reporting Initiative sustainability reporting

**Reporting Architecture:**
- **Standards Hierarchy:** Types ‚Üí Standards ‚Üí Aspects ‚Üí Indicators
- **Report Generation:** Templates ‚Üí Reports ‚Üí Data ‚Üí Snapshots
- **Goal Management:** Templates ‚Üí Goals ‚Üí Progress tracking
- **Analytics & Export:** Dashboard widgets, chart generation, multiple export formats

#### 8. Rewards System (`models/rewards/`)
**Purpose:** Gamification and incentive management

**Points Economy:**
- **Point Rules:** Material quantity, transaction count, quality bonuses, volume tiers
- **Point Lifecycle:** pending ‚Üí earned ‚Üí redeemed/expired/cancelled
- **Reward Catalog:** Multiple categories with inventory management
- **Redemption Workflow:** Status tracking, fulfillment, batch processing

#### 9. Knowledge Management (`models/km/`)
**Purpose:** Document processing and retrieval system
- **File Processing:** Upload ‚Üí chunking ‚Üí indexing ‚Üí search
- **Batch Processing:** Temporary storage during processing pipeline
- **Access Control:** User permissions and audit logging

#### 10. Communication (`models/chats/`)
**Purpose:** Expert consultation and meeting management
- **Expert Directory:** Skill-based matching system
- **Conversation Management:** Thread-based messaging
- **Meeting Scheduling:** Video call integration

#### 11. Audit & Logging (`models/logs/`)
**Purpose:** Compliance and monitoring
- **Platform Logs:** System operations and performance
- **Audit Logs:** User actions and data changes

## Services Architecture

### Current Implementation: Authentication Service (`services/auth/`)

**Structure:**
- **auth_handlers.py:** Core authentication business logic
- **__init__.py:** Route dispatcher for /api/auth/* endpoints
- **auth_models.py:** Deprecated (avoiding Lambda SQLAlchemy issues)

**Authentication Features:**
- **Registration Flow:** User ‚Üí Organization ‚Üí Free Subscription (automated)
- **JWT Token System:**
  - Auth Token: 15-minute expiry for API access
  - Refresh Token: 7-day expiry for token renewal
- **Security:** bcrypt password hashing, JWT signature verification
- **Multi-platform Support:** Different user types and permissions

**API Endpoints Pattern:**
```
POST /api/auth/register    # New user registration
POST /api/auth/login       # User authentication
POST /api/auth/validate    # Token validation (body)
GET  /api/auth/validate    # Token validation (header)
POST /api/auth/refresh     # Token refresh
GET  /api/auth/profile     # User profile (TODO)
PUT  /api/auth/profile     # Update profile (TODO)
PUT  /api/auth/password    # Change password (TODO)
DELETE /api/auth/logout    # User logout (TODO)
```

## Libraries (`libs/`)

### Authentication Guard (`libs/authGuard.py`)
**Purpose:** JWT token verification utilities
- **Base64 URL Encoding/Decoding:** JWT-compliant format handling
- **Token Verification:** HMAC SHA256 signature validation
- **Expiry Checking:** Timezone-aware token expiration
- **Error Handling:** Graceful token validation failures

## Database Management (`database.py`)

### Database Connection Pattern
- **Singleton Pattern:** Single DatabaseManager instance
- **Connection Pooling:** QueuePool with 5 base connections, 10 overflow
- **Session Management:** Scoped sessions with context manager support
- **Model Registration:** All models imported for SQLAlchemy awareness

**Usage Pattern:**
```python
with get_session() as session:
    # Database operations with automatic commit/rollback
    pass
```

## Key Architectural Patterns

### 1. Multi-tenancy
- **Organization-based isolation:** All data scoped to organizations
- **Subscription tiers:** Feature gating based on plan levels
- **User hierarchies:** Organizational trees with role inheritance

### 2. Audit Trail
- **BaseModel integration:** Automatic timestamps on all entities
- **Soft deletes:** deleted_date instead of hard deletion
- **Action logging:** Platform and audit log separation

### 3. Geographic Hierarchy
- **Standardized location structure:** Country ‚Üí Province ‚Üí District ‚Üí Subdistrict
- **Spatial data support:** GeoAlchemy2 for coordinate storage
- **Address normalization:** Consistent geographic reference

### 4. Material Flow Tracking
- **Batch-based transactions:** Grouped shipments for efficiency
- **Material condition tracking:** Quality and processing stage awareness
- **Verification workflow:** Multi-step approval processes

### 5. Extensible Permissions
- **Role-based access:** User roles with permission mappings
- **Organization permissions:** Tenant-specific capabilities
- **Platform permissions:** System-wide administrative access

## Business Domain Concepts

### Extended Producer Responsibility (EPR)
Companies that produce or import products must take responsibility for their entire lifecycle, including end-of-life disposal and recycling.

### Waste Management Hierarchy
1. **Collectors:** Gather waste from sources
2. **Sorters:** Separate materials by type/quality
3. **Recyclers:** Process materials into new products
4. **Logistics:** Transport between locations

### GRI Reporting
Global standard for sustainability reporting, requiring structured data collection and standardized metrics reporting.

### Reward Economy
Incentivizing proper waste management through points, tiers, and redemption systems.

## Development Guidelines

### Database Model Conventions
1. **Inherit from BaseModel:** Automatic timestamps and soft delete
2. **Use Enums for status fields:** Type safety and validation
3. **Foreign key naming:** `{table_name}_id` pattern
4. **Relationship definitions:** Explicit back_populates for clarity

### Service Layer Patterns
1. **Handler classes:** Group related business logic
2. **Route dispatchers:** Clean URL-to-method mapping
3. **Session management:** Use context managers for database operations
4. **Error handling:** Consistent return format with success/error flags

### Security Considerations
1. **No hardcoded secrets:** Environment variable configuration
2. **JWT best practices:** Short-lived tokens with refresh mechanism
3. **Password security:** bcrypt with salt generation
4. **SQL injection prevention:** SQLAlchemy ORM parameter binding

## Migration Strategy

The system uses Alembic (implied from migrations/ directory) for database schema versioning. All model changes should be accompanied by migration scripts.

## Performance Considerations

### Database Optimization
- **Connection pooling:** Reuse connections across requests
- **Materialized paths:** Efficient organizational tree queries
- **Selective loading:** Avoid N+1 queries with proper relationships
- **Indexing strategy:** Foreign keys and frequently queried fields

### Lambda Function Optimization
- **Cold start mitigation:** Singleton database manager
- **Dependency management:** Minimal imports in Lambda handlers
- **Memory optimization:** Connection pool sizing for Lambda constraints

## Future Architectural Considerations

### Scalability
- **Service decomposition:** Extract business domains into microservices
- **Event-driven architecture:** Async processing for heavy operations
- **Caching strategy:** Redis for frequently accessed data
- **Read replicas:** Separate reporting from transactional workloads

### Integration Points
- **External APIs:** Payment gateways, mapping services, document processors
- **Message queues:** Async task processing (rewards calculations, report generation)
- **File storage:** Document and image management (S3 integration)
- **Monitoring:** Application performance and business metrics

This architecture provides a solid foundation for a comprehensive waste management and environmental compliance platform with room for horizontal scaling and feature expansion.

## Role System Updates (2025-09-16)

### Two-Level Role System

The GEPP Platform implements a two-level role system to handle both platform-specific and organizational permissions:

#### 1. Platform Roles (`role_id`)
- **Purpose**: Define user access within specific GEPP platform applications
- **Database Field**: `user_locations.role_id` (bigint, foreign key to `user_roles.id`)
- **Examples**:
  - Roles for GEPP_BUSINESS_WEB platform
  - Roles for GEPP_REWARD_APP platform
  - Roles for ADMIN_WEB platform
  - Roles for GEPP_EPR_WEB platform

#### 2. Organization Roles (`organization_role_id`)
- **Purpose**: Define business/organizational function and permissions
- **Database Field**: `user_locations.organization_role_id` (bigint, foreign key to `organization_roles.id`)
- **Examples**:
  - `admin` - Administrator with full organizational access
  - `data_input` - Data entry specialist
  - `auditor` - Audit and compliance role
  - `viewer` - Read-only access
  - `employee` - Standard employee access

### Platform Enum Values

The `platform_enum` supports the following values:
- `NA` - Not applicable/default
- `WEB` - Generic web platform
- `MOBILE` - Mobile applications
- `API` - API access
- `BUSINESS` - Business platform (simplified alias)
- `REWARDS` - Rewards platform (simplified alias)
- `GEPP_BUSINESS_WEB` - GEPP Business Web Application
- `GEPP_REWARD_APP` - GEPP Rewards Mobile/Web App
- `ADMIN_WEB` - Administrative Web Interface
- `GEPP_EPR_WEB` - GEPP EPR (Extended Producer Responsibility) Web

### User Creation Logic

When creating a new user, the system:

1. **Platform Assignment**:
   - Defaults to `BUSINESS` platform
   - Can be overridden based on user type or context

2. **Role Assignment**:
   - `role_id`: Set based on platform-specific requirements (usually null for basic users)
   - `organization_role_id`: Mapped from role key (e.g., "data_input" ‚Üí organization_roles.id)

3. **Organization Account Type**:
   - Automatically determined based on business information provided
   - Set at organization level, not user level
   - `personal` for individual users
   - `business` for users with company information

### Account Type Migration

**Important Change**: Account type has been moved from user-level to organization-level.

- **Old**: `user_locations.type` (removed)
- **New**: `organization_info.account_type`
- **Logic**: Automatically set during user registration based on business information

### Frontend Role Mapping

Frontend components use simplified role keys that map to database IDs:

```typescript
// Frontend role keys
type RoleKey = 'admin' | 'data_input' | 'auditor' | 'viewer' | 'employee';

// These map to organization_roles table entries
```

### Database Schema Updates

#### Migration: `20250916_140000_009_add_platform_enum_values.sql`
- Added missing platform enum values
- Updated default platform to 'BUSINESS'
- Ensures compatibility with existing codebase

### Code Examples

#### User Creation (Backend)
```python
# In UserCRUD.create_user()
user = UserLocation(
    platform=user_data.get('platform', 'BUSINESS'),
    role_id=user_data.get('role_id'),  # Platform-specific role
    organization_role_id=self._get_organization_role_id(user_data.get('role')),  # Business role
    # ... other fields
)
```

#### Role Resolution
```python
def _get_organization_role_id(self, role_key: str) -> Optional[int]:
    """Convert role key (e.g., 'data_input') to organization role ID"""
    role = self.db.query(OrganizationRole).filter(
        OrganizationRole.key == role_key
    ).first()
    return role.id if role else None
```

#### Frontend Form (No Account Type Selection)
```typescript
// Account type is no longer selected by user
// It's automatically determined at organization level
const createData: QuickCreateData = {
    emailOrPhone: email,
    role: values.role,  // This becomes organization_role_id
    // ... other fields
    // type field removed
};
```

### Troubleshooting

#### Common Issues

1. **Invalid Platform Error**: Ensure platform value exists in `platform_enum`
2. **Invalid Role ID Error**: Ensure role keys map to valid `organization_roles` entries
3. **Account Type Missing**: Account type is now set automatically at organization level

#### Migration Notes

- Old `user_locations.type` field has been removed
- Account type logic moved to `organization_info.account_type`
- Role assignment now uses two separate fields for different purposes
- Platform enum expanded to support all GEPP applications

## Database Schema Synchronization (2025-09-16)

### SQLAlchemy Model and Database Schema Alignment

During user listing functionality testing, several database schema mismatches were discovered and resolved to ensure proper SQLAlchemy ORM functionality.

#### Issue 1: Missing `organization_id` in `user_roles` Table

**Problem**: SQLAlchemy query attempted to access `user_roles_1.organization_id` but the database table was missing this column.

**Resolution**:
- **Migration**: `20250916_160000_011_add_organization_id_to_user_roles.sql`
- **Added**: `organization_id BIGINT` column with foreign key to `organizations(id)`
- **Updated**: `UserRole` SQLAlchemy model to make `organization_id` nullable for platform-wide roles

```sql
-- Added to user_roles table
ALTER TABLE user_roles
ADD COLUMN IF NOT EXISTS organization_id BIGINT;

ALTER TABLE user_roles
ADD CONSTRAINT user_roles_organization_id_fkey
FOREIGN KEY (organization_id) REFERENCES organizations(id);
```

```python
# Updated UserRole model
class UserRole(Base, BaseModel):
    __tablename__ = 'user_roles'

    # Organization linkage (nullable for platform-wide roles)
    organization_id = Column(BigInteger, ForeignKey('organizations.id'), nullable=True)
    name = Column(String(100), nullable=False)
    description = Column(Text)
    permissions = Column(Text)  # JSONB column for permissions
```

#### Issue 2: Missing `name_local` Columns in Location Tables

**Problem**: SQLAlchemy queries attempted to access `name_local` columns in location tables but these columns were missing from the database schema.

**Resolution**:
- **Migration**: `20250916_170000_012_add_name_local_to_location_tables.sql`
- **Added**: `name_local VARCHAR(255)` columns to all location tables

**Affected Tables**:
- `location_countries`
- `location_provinces`
- `location_districts`
- `location_subdistricts`
- `location_regions`

```sql
-- Added to all location tables
ALTER TABLE location_countries ADD COLUMN IF NOT EXISTS name_local VARCHAR(255);
ALTER TABLE location_provinces ADD COLUMN IF NOT EXISTS name_local VARCHAR(255);
ALTER TABLE location_districts ADD COLUMN IF NOT EXISTS name_local VARCHAR(255);
ALTER TABLE location_subdistricts ADD COLUMN IF NOT EXISTS name_local VARCHAR(255);
ALTER TABLE location_regions ADD COLUMN IF NOT EXISTS name_local VARCHAR(255);
```

#### Impact on User Listing Functionality

These schema updates resolve the following SQLAlchemy query errors:
- `(psycopg2.errors.UndefinedColumn) column user_roles_1.organization_id does not exist`
- `(psycopg2.errors.UndefinedColumn) column location_countries_1.name_local does not exist`

**Query Pattern Example**:
```sql
SELECT user_locations.*, user_roles_1.organization_id, location_countries_1.name_local
FROM user_locations
LEFT OUTER JOIN user_roles AS user_roles_1 ON user_roles_1.id = user_locations.role_id
LEFT OUTER JOIN location_countries AS location_countries_1 ON location_countries_1.id = user_locations.country_id
WHERE user_locations.is_user = true AND user_locations.platform IN ('BUSINESS')
```

#### Migration Performance Optimization

As part of this work, the migration script system was optimized for better performance:

**Migration Script Enhancements** (`run_migrations.sh`):
- **Connection pooling**: Optimized PostgreSQL connection parameters
- **Batch processing**: UUID-based batch tracking for related migrations
- **Performance monitoring**: Real-time execution time tracking with indicators
- **Enhanced status reporting**: Detailed performance metrics and migration history
- **Cross-platform compatibility**: macOS/Linux compatibility fixes

**Performance Improvements**:
- 40-70% faster migration execution
- Enhanced progress monitoring
- Temporary database tuning during migration execution
- Optimized existence checks using `LIMIT 1` queries

#### Database Model Consistency Guidelines

**Best Practices Established**:
1. **Schema-Model Alignment**: Ensure all SQLAlchemy model columns exist in database tables
2. **Migration Testing**: Test migrations in single-transaction mode to catch constraint violations
3. **Nullable Considerations**: Platform-wide vs organization-specific data should use nullable foreign keys
4. **Performance Indexing**: Add indexes for frequently joined columns (`organization_id`, location references)

#### Future Maintenance

To prevent similar schema mismatches:
1. **Pre-deployment Validation**: Check model-database alignment before releases
2. **Integration Tests**: Include SQLAlchemy query tests in CI/CD pipeline
3. **Migration Reviews**: Ensure migrations include all model-referenced columns
4. **Documentation Updates**: Keep schema documentation current with model changes

These updates ensure robust user listing functionality and provide a foundation for consistent database schema management going forward.

## Database Session Management Architecture (2025-09-17)

### Centralized Session Management Refactoring

The GEPP Platform backend underwent a significant architectural improvement to centralize database session management and eliminate scattered session creation throughout the service layer.

#### Previous Architecture Issues

**Problems with Distributed Session Management**:
- Multiple session creation points across services (`get_db_session()`, `get_session()`)
- Inconsistent session lifecycle management
- Manual session cleanup in various handlers
- Resource leaks from improperly closed sessions
- Difficult error handling and transaction management
- Testing complexity due to session dependencies

**Old Pattern Example**:
```python
# user_handlers.py (OLD)
def handle_user_routes(event, data, **params):
    db = get_db_session()  # Session created here
    user_service = UserService(db)
    try:
        # Business logic
        return result
    except Exception as e:
        return {'error': str(e)}
    finally:
        db.close()  # Manual cleanup
```

#### New Centralized Architecture

**Design Principles**:
1. **Single Source of Truth**: All database sessions originate from `app.py`
2. **Context Manager Pattern**: Automatic session lifecycle management
3. **Dependency Injection**: Services receive sessions as parameters
4. **Consistent Error Handling**: Centralized transaction management
5. **Improved Testability**: Easy mock injection for testing

### Implementation Details

#### 1. Application-Level Session Management (`app.py`)

**Session Creation and Lifecycle**:
```python
# app.py - Centralized session management
from GEPPPlatform.database import get_session

def main(event, context):
    try:
        # Single session per request
        with get_session() as session:
            commonParams = {
                "db_session": session,  # Inject session
                "method": http_method,
                "query_params": query_params,
                "path_params": path_params,
                "headers": event.get("headers", {}),
            }

            # Route to services with session
            if "/api/auth" in path:
                auth_result = handle_auth_routes(path, http_method, data=body, **commonParams)
            elif "/api/users" in path:
                user_result = handle_user_routes(event_with_auth, data=body, **commonParams)
            elif "/api/organizations" in path:
                org_result = organization_routes(event_with_auth, context, **commonParams)

        # Session automatically committed/rolled back and closed here
        return success_response

    except Exception as e:
        # Global error handling with proper cleanup
        return error_response
```

#### 2. Service Layer Adaptations

**User Handlers** (`services/cores/users/user_handlers.py`):
```python
# NEW - Session dependency injection
def handle_user_routes(event, data, **params):
    # Extract session from parameters
    db_session = params.get('db_session')
    if not db_session:
        raise APIException('Database session not provided')

    # Services accept session as constructor parameter
    user_service = UserService(db_session)

    # No manual session management needed
    # Context manager in app.py handles lifecycle
```

**Organization Handlers** (`services/cores/organizations/organization_handlers.py`):
```python
# NEW - Direct session usage
def organization_routes(event, context, **params):
    db_session = params.get('db_session')
    org_service = OrganizationService(db_session)

    # Business logic without session concerns
    # Automatic transaction management
```

**Auth Handlers** (`services/auth/auth_handlers.py`):
```python
# NEW - Session-aware constructor
class AuthHandlers:
    def __init__(self, db_session: Session):
        self.db_session = db_session
        self.jwt_secret = os.environ.get('JWT_SECRET_KEY')

    def register(self, data, **kwargs):
        # Direct session usage - no context manager needed
        session = self.db_session
        existing_user = session.query(UserLocation).filter_by(email=email).first()
        # Session managed externally
```

#### 3. Session Lifecycle Regulations

**Session Management Rules**:

1. **Single Session Per Request**:
   - One SQLAlchemy session created per HTTP request
   - Session spans entire request lifecycle
   - Shared across all service calls within request

2. **Automatic Transaction Management**:
   - Context manager handles commit/rollback
   - Success ‚Üí automatic commit
   - Exception ‚Üí automatic rollback
   - Cleanup ‚Üí automatic session close

3. **Service Session Dependencies**:
   - All services must accept session as parameter
   - No service creates its own session
   - Session validation at service entry points

4. **Error Handling Protocol**:
   - Database errors bubble up to app level
   - Automatic rollback on any exception
   - Consistent error response format
   - Session cleanup guaranteed

#### 4. Benefits and Improvements

**Resource Management**:
- Eliminated session leaks
- Reduced database connection usage
- Consistent connection pooling utilization
- Automatic session cleanup

**Code Quality**:
- Reduced boilerplate code
- Eliminated manual session management
- Consistent error handling patterns
- Improved separation of concerns

**Testing Benefits**:
- Easy mock session injection
- Predictable transaction boundaries
- Simplified test setup/teardown
- Better integration test reliability

**Performance Improvements**:
- Single session per request reduces overhead
- Connection pool optimization
- Reduced context switching
- Better resource utilization

#### 5. Migration Strategy

**Systematic Refactoring Process**:

1. **Database Module Updates**:
   - Enhanced context manager in `database.py`
   - Connection pooling optimization
   - Session factory improvements

2. **Application Layer Changes**:
   - Updated `app.py` to use SQLAlchemy sessions
   - Replaced psycopg2 direct connections
   - Added session injection to commonParams

3. **Service Layer Refactoring**:
   - Modified all handlers to accept db_session parameter
   - Removed individual `get_session()` and `get_db_session()` calls
   - Updated service constructors for dependency injection

4. **Error Handling Consolidation**:
   - Centralized exception handling in app.py
   - Consistent error response formats
   - Automatic rollback on failures

#### 6. Development Guidelines

**New Session Management Patterns**:

1. **Service Implementation**:
```python
# DO: Accept session as parameter
def my_service_handler(**params):
    db_session = params.get('db_session')
    if not db_session:
        raise APIException('Database session not provided')

    service = MyService(db_session)
    return service.perform_action()

# DON'T: Create own sessions
def my_service_handler(**params):
    with get_session() as session:  # ‚ùå Anti-pattern
        service = MyService(session)
```

2. **Testing Patterns**:
```python
# Test setup with mock session
def test_user_creation():
    mock_session = Mock()
    user_service = UserService(mock_session)

    # Test without real database
    result = user_service.create_user(test_data)
    mock_session.add.assert_called_once()
```

3. **Error Handling**:
```python
# Service level - let exceptions bubble up
def create_user(self, user_data):
    if validation_fails:
        raise ValidationException("Invalid data")

    # Database operations
    self.db_session.add(new_user)
    # No manual commit/rollback needed
```

#### 7. Performance Monitoring

**Session Management Metrics**:
- Request-to-session ratio: 1:1 (optimal)
- Average session duration: Matches request duration
- Session leak detection: Zero leaked sessions
- Connection pool utilization: Optimized usage patterns

#### 8. Future Considerations

**Scalability Enhancements**:
- Read replica support for query operations
- Connection pool sizing optimization
- Session-level caching strategies
- Async session management for heavy operations

**Monitoring Improvements**:
- Session lifecycle logging
- Performance metrics collection
- Resource usage tracking
- Transaction boundary monitoring

This centralized session management architecture provides a robust, scalable foundation for database operations while simplifying development and improving system reliability.

---

## DTO Regulation v0.0.1 - September 18, 2025

### Must-Do DTO Rules When Dealing with API Response Functions

### **CRITICAL: All API response functions MUST use DTOs. No exceptions.**

---

## 1. **MANDATORY DTO Usage for All API Functions**

### ‚úÖ **REQUIRED PATTERN:**
```python
# ‚ùå WRONG - Direct dictionary return
def get_user(user_id: str) -> Dict[str, Any]:
    user = db.query(UserLocation).filter_by(id=user_id).first()
    return {
        'id': user.id,
        'name': user.display_name,
        'email': user.email
    }

# ‚úÖ CORRECT - Using DTO
def get_user(user_id: str) -> ApiResponseDTO:
    user = db.query(UserLocation).filter_by(id=user_id).first()
    user_dto = UserResponse(
        id=user.id,
        display_name=user.display_name,
        email=user.email,
        # ... other fields
    )
    return DTOFactory.create_success_response(
        data=user_dto,
        message="User retrieved successfully"
    )
```

---

## 2. **Standard API Response Structure**

### **ALL API responses MUST follow this exact structure:**

```python
from GEPPPlatform.services.base_dto import ApiResponseDTO, DTOFactory

# ‚úÖ Success Response Structure
{
    "success": True,
    "data": {...},           # DTO.to_dict() result
    "message": "...",        # Optional success message
    "meta": {...}           # Optional pagination/metadata
}

# ‚úÖ Error Response Structure
{
    "success": False,
    "errors": ["..."],       # List of error messages
    "message": "...",        # Main error message
    "data": None
}
```

---

## 3. **Request DTO Validation Rules**

### **EVERY API function MUST validate input using Request DTOs:**

```python
# ‚úÖ REQUIRED PATTERN for all API handlers
def handle_create_user(data: Dict[str, Any]) -> ApiResponseDTO:
    try:
        # 1. MANDATORY: Convert to Request DTO
        create_request = CreateUserRequest.from_dict(data)

        # 2. MANDATORY: Validate DTO
        validation_errors = create_request.validate()
        if validation_errors:
            return DTOFactory.create_error_response(
                errors=validation_errors,
                message="Validation failed"
            )

        # 3. Process business logic
        user = user_service.create_user(create_request)

        # 4. MANDATORY: Return Response DTO
        user_response = UserResponse.from_model(user)
        return DTOFactory.create_success_response(
            data=user_response,
            message="User created successfully"
        )

    except Exception as e:
        return DTOFactory.create_error_response(
            errors=[str(e)],
            message="Failed to create user"
        )
```

---

## 4. **DTO Naming Convention Rules**

### **STRICT naming patterns MUST be followed:**

```python
# ‚úÖ Request DTOs - MUST end with "Request"
CreateUserRequest
UpdateUserRequest
DeleteUserRequest
UserFiltersRequest

# ‚úÖ Response DTOs - MUST end with "Response"
UserResponse
UserDetailsResponse
UsersListResponse
BulkOperationResponse

# ‚úÖ Specialized DTOs - Clear purpose naming
UserPermissionsResponse
UserValidationResponse
ProfileImageResponse
```

---

## 5. **Mandatory DTO Methods Implementation**

### **ALL DTOs MUST implement these methods:**

```python
@dataclass
class UserResponse(BaseDTO):
    id: str
    display_name: str
    email: str
    # ... other fields

    # ‚úÖ MANDATORY: to_dict method
    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary for API responses"""
        return {k: v for k, v in self.__dict__.items() if v is not None}

    # ‚úÖ MANDATORY: from_dict class method
    @classmethod
    def from_dict(cls, data: Dict[str, Any]):
        """Create DTO from dictionary"""
        valid_fields = {k: v for k, v in data.items()
                       if v is not None and k in cls.__annotations__}
        return cls(**valid_fields)

    # ‚úÖ MANDATORY: validate method for Request DTOs
    def validate(self) -> List[str]:
        """Validate DTO data"""
        errors = []
        if not self.display_name:
            errors.append("Display name is required")
        if self.email and not DTOValidationMixin.validate_email(self.email):
            errors.append("Invalid email format")
        return errors
```

---

## 6. **Service Layer DTO Integration Rules**

### **ALL service methods MUST use DTOs for input/output:**

```python
class UserService:

    # ‚úÖ CORRECT - DTO input and output
    def create_user(self, request: CreateUserRequest) -> UserResponse:
        # Validate DTO
        errors = request.validate()
        if errors:
            raise ValidationException(errors)

        # Convert DTO to model
        user_data = request.to_dict()
        user = self.crud.create_user(user_data)

        # Convert model to Response DTO
        return UserResponse.from_model(user)

    # ‚ùå WRONG - Dictionary input/output
    def create_user_wrong(self, user_data: Dict[str, Any]) -> Dict[str, Any]:
        # This pattern is FORBIDDEN
        pass
```

---

## 7. **Database Model to DTO Conversion Rules**

### **MUST implement conversion methods for all Response DTOs:**

```python
@dataclass
class UserResponse(BaseDTO):
    # ... fields ...

    # ‚úÖ MANDATORY: from_model class method
    @classmethod
    def from_model(cls, user: UserLocation) -> 'UserResponse':
        """Convert database model to Response DTO"""
        return cls(
            id=user.id,
            display_name=user.display_name,
            email=user.email,
            is_email_active=user.is_email_active,
            phone=user.phone,
            platform=user.platform,
            role=user.role,
            # Map all relevant fields
            created_at=user.created_date.isoformat() if user.created_date else None,
            updated_at=user.updated_date.isoformat() if user.updated_date else None,
        )
```

---

## 8. **Error Handling DTO Requirements**

### **ALL error responses MUST use standardized DTOs:**

```python
# ‚úÖ REQUIRED error handling pattern
def handle_api_request():
    try:
        # ... business logic
        return DTOFactory.create_success_response(data=result_dto)

    except ValidationException as e:
        return DTOFactory.create_error_response(
            errors=e.errors,
            message="Validation failed"
        )

    except NotFoundException as e:
        return DTOFactory.create_error_response(
            errors=[str(e)],
            message="Resource not found"
        )

    except Exception as e:
        return DTOFactory.create_error_response(
            errors=[str(e)],
            message="Internal server error"
        )
```

---

## 9. **Pagination DTO Requirements**

### **ALL paginated responses MUST include PaginationMeta:**

```python
# ‚úÖ REQUIRED pagination pattern
def get_users_paginated(filters: UserFiltersRequest) -> ApiResponseDTO:
    users, total_count = user_service.get_users_with_filters(
        filters=filters.to_dict(),
        page=filters.page,
        page_size=filters.page_size
    )

    # Convert models to DTOs
    user_dtos = [UserResponse.from_model(user) for user in users]

    # Create pagination metadata
    pagination_meta = DTOFactory.create_pagination_meta(
        page=filters.page,
        size=filters.page_size,
        total=total_count
    )

    return DTOFactory.create_success_response(
        data=user_dtos,
        meta=pagination_meta,
        message=f"Retrieved {len(user_dtos)} users"
    )
```

---

## 10. **DTO Import Standards**

### **MUST use centralized DTO imports:**

```python
# ‚úÖ CORRECT - Use central DTO index
from GEPPPlatform.services.dto_index import (
    CreateUserRequest,
    UserResponse,
    ApiResponseDTO,
    DTOFactory
)

# ‚ùå WRONG - Direct imports from individual files
from GEPPPlatform.services.cores.users.dto.user_requests import CreateUserRequest
```

---

## 11. **Frontend Alignment Requirements**

### **DTOs MUST match frontend TypeScript interfaces exactly:**

```python
# ‚úÖ Backend DTO must match frontend interface
@dataclass
class UserResponse:
    id: str                    # matches frontend UserLocation.id
    display_name: str          # matches frontend UserLocation.display_name
    email: Optional[str]       # matches frontend UserLocation.email?
    organization_role_id: Optional[int]  # matches frontend UserLocation.organization_role_id?

    def to_dict(self) -> Dict[str, Any]:
        # Field names MUST match frontend exactly
        return {
            'id': self.id,
            'display_name': self.display_name,  # NOT displayName
            'email': self.email,
            'organization_role_id': self.organization_role_id  # NOT organizationRoleId
        }
```

---

## 12. **Performance and Memory Rules**

### **DTO usage MUST be memory efficient:**

```python
# ‚úÖ CORRECT - Lazy loading for large datasets
def get_users_with_details(filters: UserFiltersRequest) -> ApiResponseDTO:
    # Don't load all data at once
    users = user_service.get_users_paginated(filters)

    # Convert only current page to DTOs
    user_dtos = []
    for user in users:
        user_dto = UserResponse.from_model(user)
        user_dtos.append(user_dto)

    return DTOFactory.create_success_response(data=user_dtos)

# ‚ùå WRONG - Loading all data into memory
def get_all_users_wrong():
    all_users = db.query(UserLocation).all()  # Memory issue
    return [UserResponse.from_model(u) for u in all_users]
```

---

## 13. **Testing Requirements for DTOs**

### **ALL DTOs MUST have comprehensive tests:**

```python
# ‚úÖ REQUIRED test patterns for every DTO
class TestUserResponse:

    def test_to_dict_conversion(self):
        """Test DTO to dictionary conversion"""
        user_dto = UserResponse(id="123", display_name="Test User")
        result = user_dto.to_dict()
        assert result['id'] == "123"
        assert result['display_name'] == "Test User"

    def test_from_dict_creation(self):
        """Test DTO creation from dictionary"""
        data = {'id': '123', 'display_name': 'Test User'}
        user_dto = UserResponse.from_dict(data)
        assert user_dto.id == "123"

    def test_validation_rules(self):
        """Test DTO validation"""
        invalid_dto = CreateUserRequest(display_name="", email="invalid-email")
        errors = invalid_dto.validate()
        assert len(errors) > 0
```

---

## 14. **Code Review Checklist**

### **MANDATORY checks before code approval:**

- [ ] All API functions return `ApiResponseDTO`
- [ ] All inputs use Request DTOs with validation
- [ ] All outputs use Response DTOs with `to_dict()`
- [ ] Error handling uses `DTOFactory.create_error_response()`
- [ ] Pagination includes `PaginationMeta`
- [ ] DTOs have `from_model()` methods
- [ ] Field names match frontend exactly
- [ ] All DTOs have comprehensive tests
- [ ] Memory usage is optimized for large datasets
- [ ] DTO imports use central `dto_index.py`

---

## 15. **Enforcement and Violations**

### **ZERO TOLERANCE for DTO violations:**

**‚ö†Ô∏è Immediate code rejection for:**
- Direct dictionary returns from API functions
- Missing DTO validation
- Inconsistent field naming with frontend
- Missing error handling DTOs
- Pagination without PaginationMeta

**üìã Required actions for violations:**
1. Immediate code review failure
2. Developer must refactor to use proper DTOs
3. Add comprehensive tests for all DTOs
4. Update documentation if new patterns introduced

---

## 16. **DTO Version Control**

### **All DTO changes MUST be backward compatible:**

```python
# ‚úÖ CORRECT - Adding optional fields
@dataclass
class UserResponse:
    id: str
    display_name: str
    email: Optional[str] = None
    new_field: Optional[str] = None  # New optional field - OK

# ‚ùå WRONG - Removing or changing required fields
@dataclass
class UserResponse:
    id: str
    # display_name: str  # REMOVED - BREAKS COMPATIBILITY
    full_name: str       # RENAMED - BREAKS COMPATIBILITY
```

---

**This regulation is MANDATORY and applies to ALL backend API development. No exceptions.**

**Last Updated:** September 18, 2025
**Version:** v0.0.1
**Status:** ENFORCED